# main.py
import cv2
import torch
import numpy as np
from pathlib import Path
from ultralytics import YOLO
from boxmot import BoostTrack
from utils.draw import draw_bbox, draw_keypoints, draw_arrow, draw_zone
from utils.zone import count_in_zone
import config
import datetime
import time
import psutil
from collections import deque  # th√™m ƒë·ªÉ l∆∞u history
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# --------------------
# H√†m ph·∫£n chi·∫øu vector qua vector tham chi·∫øu
# --------------------
def reflect_vector(vec, ref_vec):
    ref_unit = ref_vec / np.linalg.norm(ref_vec)
    dot = np.dot(vec, ref_unit)
    return 2*dot*ref_unit - vec

def compute_direction_from_keypoints(kpts):
    """
    kpts: (K,2) keypoints pixel
    Tr·∫£ v·ªÅ vector h∆∞·ªõng t·ªïng (unit) t·ª´ keypoint 1
    """
    if len(kpts) < 5:
        return None

    head = np.array(kpts[0], dtype=np.float32)  # keypoint 1
    pt2 = np.array(kpts[1], dtype=np.float32)
    pt3 = np.array(kpts[2], dtype=np.float32)
    pt4 = np.array(kpts[3], dtype=np.float32)
    pt5 = np.array(kpts[4], dtype=np.float32)

    # Vector 3->1 (tham chi·∫øu)
    vec_3to1 = head - pt3

    vectors = [vec_3to1]

    # C√°c vector kh√°c 2->1,4->1,5->1 ph·∫£n chi·∫øu qua 3->1
    for pt in [pt2, pt4, pt5]:
        if np.any(pt > 0):
            vec = head - pt
            if np.linalg.norm(vec_3to1) > 0:
                vec = reflect_vector(vec, vec_3to1)
            vectors.append(vec)

    # Vector t·ªïng
    vec_total = np.sum(vectors, axis=0)
    norm = np.linalg.norm(vec_total)
    if norm > 0:
        vec_unit = vec_total / norm
    else:
        vec_unit = None

    return vec_unit



def main():
    print("üîπ Loading YOLO model...")
    model = YOLO(config.YOLO_WEIGHTS)

    print("üîπ Initializing tracker...")
    tracker = BoostTrack(
        reid_weights=Path(config.REID_WEIGHTS),
        device=device,
        half=False
    )

    # L∆∞u history ƒëi·ªÉm ƒë·∫ßu cho m·ªói con t·∫±m
    track_history = {}  # track_id -> deque of head points

    cap = cv2.VideoCapture(config.VIDEO_INPUT)
    frame_count = 0
    start_time = time.time()
    process = psutil.Process()
    max_ram = 0
    if not cap.isOpened():
        print(f"‚ùå Cannot open video: {config.VIDEO_INPUT}")
        return
    fps = cap.get(cv2.CAP_PROP_FPS)
    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(config.VIDEO_OUTPUT, fourcc, fps, (w, h))

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        results = model(frame, verbose=False)[0]

        boxes = results.boxes.xyxy.cpu().numpy()
        confs = results.boxes.conf.cpu().numpy()
        classes = results.boxes.cls.cpu().numpy()

        if results.keypoints is not None:
            keypoints = results.keypoints.xy.cpu().numpy()
        else:
            keypoints = []

        detections = np.column_stack((boxes, confs, classes)) if len(boxes) > 0 else np.empty((0, 6))
        tracks = tracker.update(detections, frame)

        # Duy·ªát qua t·ª´ng track
        for t in tracks:
            x1, y1, x2, y2, track_id, cls_id, conf = t[:7]
            draw_bbox(frame, (x1, y1, x2, y2), track_id=track_id)

            # t√¨m keypoint head trong bbox
            for kps in keypoints:
                head = kps[0]  # ƒëi·ªÉm ƒë·∫ßu l√† keypoint 1 (index 0)
                if x1 <= head[0] <= x2 and y1 <= head[1] <= y2:
                    # L∆∞u v√†o history
                    if track_id not in track_history:
                        track_history[track_id] = deque(maxlen=10)  # l∆∞u t·ªëi ƒëa 50 ƒëi·ªÉm
                    track_history[track_id].append(tuple(head.astype(int)))

                    # V·∫Ω keypoints
                    draw_keypoints(frame, kps)

                    # V·∫Ω vector h∆∞·ªõng
                    dir_vec = compute_direction_from_keypoints(kps)
                    if dir_vec is not None:
                        start_pt = tuple(head.astype(int))
                        end_pt = tuple((head + dir_vec*50).astype(int))
                        cv2.arrowedLine(frame, start_pt, end_pt, (0, 0, 255), 2, tipLength=0.3)

                    # V·∫Ω qu·ªπ ƒë·∫°o c·ªßa ri√™ng track_id n√†y
                    pts = list(track_history[track_id])
                    if len(pts) > 1:
                        for i in range(1, len(pts)):
                            cv2.line(frame, pts[i-1], pts[i], (255, 0, 0), 2)

                    break  # ch·ªâ c·∫ßn 1 b·ªô keypoint kh·ªõp v·ªõi bbox

        # V√πng
        for zone_name, zone_points in config.REGIONS.items():
            draw_zone(frame, zone_points)
            bboxes = tracks[:, :4] if len(tracks) > 0 else np.empty((0, 4))
            count = count_in_zone(tracks, zone_points, bboxes)
            cv2.putText(
                frame,
                f"{zone_name}: {count}",
                (zone_points[0][0], zone_points[0][1] - 10),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.7,
                (0, 255, 255),
                2
            )

        frame_count += 1
        ram_usage = process.memory_info().rss / (1024 * 1024)
        if ram_usage > max_ram:
            max_ram = ram_usage

        out.write(frame)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    out.release()
    cv2.destroyAllWindows()

    elapsed = time.time() - start_time
    avg_fps = frame_count / elapsed if elapsed > 0 else 0
    print(f"\n---\nProcessed {frame_count} frames in {elapsed:.2f} seconds.")
    print(f"Average FPS: {avg_fps:.2f}")
    print(f"Peak RAM usage: {max_ram:.2f} MB")


if __name__ == "__main__":
    main()
